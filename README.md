# 基於深度學習影像辨識之手語轉文字翻譯
## 摘要：
### 手語一直是聾啞人士重要的溝通方式，但是一般人不一定會認識手語，這對於聾啞人士的溝通而言非常不便，舉凡問路抑或是日常生活的小事等，皆需要受過專業訓練的人士來進行翻譯，實不損友善環境之美名。因此，針對此，我們擬運用深度學習的技術，配合影像辨識的方法，實現可以將手語直接轉譯文字的工作。
##  研究動機:
### 某天，小組成員一起去吃飯時遇到了需要幫忙的聾啞人士，當那位人士比出一連串的手語時，面對毫無手語基礎的我們，雙方在溝通上產生了障礙，因此，為了應對未來再遇到相同的情形，開發手語轉文字的裝置，期許有助於解決與聾啞人士之間的溝通有所幫助。
## 研究目的
### 全球各地皆有聾啞人士需要社會上的關懷，雖然手語的發明讓他們能夠順暢的交流，但一般人並不一定會知曉手語的指法，這項問題便使得聾啞人士與一般人的溝通仍有隔閡。因此，我們希望透過深度學習影像辨識的方式去實現手語轉換文字翻譯。讓日後我們可以透過簡易的裝置(如手機，平板等)就可以當場翻譯手語。因應不同語言的隔閡因此產生了語言翻譯的工作，語言的轉譯從靠人力，一直開發到專業的翻譯設備，再延伸至以手機app實現。然而手語同卻因為其呈現的方式侷限了翻譯可能性。單看字彙量上，手語仍有許多字詞無法翻譯出來，此時，面對此種困境歐美國家會使用單字將該詞拼湊出來，而臺灣手語協會則應用注音的方式將文字拼出，因此在將來擴充手語單字量時，也會考慮最為基本的注音以及字母，整體翻成文字的可能性亦將飛躍性的增加。因此希望透過本次的研究，可以讓手語的翻譯更為容易，並期許此成為與聾啞人士形成全新的溝通管道。
##  研究方法
 ### 首先應用Mediapipe進行手部及臉部的特徵擷取，擷取的結果將是節點，這些節點分別代表著位置資訊，因此，將這些節點輸入到LSTM模型裡面進行訓練，最後可以得到辨識手語並轉為文字的模型。其中，甚至可以運用seq2seq架構下的transformer進行最終輸出文字的梳理，讓輸出的字句文法更加流暢。

